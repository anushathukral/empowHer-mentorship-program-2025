{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86239f5b-6d75-4361-a852-e95273563d0c",
   "metadata": {},
   "source": [
    "# Day 3 - Girls in Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad834a40-7cb3-4b67-b14c-6926d6dc91a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.3     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.1.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.5     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.2.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.1.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.3\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.1.1     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.2.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.8     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Learn how to get started at \u001b[32mhttps://www.tidymodels.org/start/\u001b[39m\n",
      "\n",
      "\n",
      "Attaching package: ‘palmerpenguins’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:modeldata’:\n",
      "\n",
      "    penguins\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(palmerpenguins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c957d-2bee-4c11-8b71-02c471d5585d",
   "metadata": {},
   "source": [
    "## Day 3 Learning Objectives\n",
    "\n",
    "- Compute the Euclidean distance between points on a graph\n",
    "- Implement the K-nearest neighbours classification algorithm\n",
    "- Describe the importance of a training and test set in machine learning\n",
    "- Explain the use and importance of cross-validation \n",
    "- Compare and contrast a variety of performance metrics\n",
    "- Execute the K-nearest neighbours regression algorithm \n",
    "- Understand the difference between regression and classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715d011-992f-4991-9d44-0cf00831e38e",
   "metadata": {},
   "source": [
    "# 1. Classification \n",
    "\n",
    "**Machine learning** is a field where computers learn from data and make decisions and predictions. **Classification** is a type of machine learning, where the goal is to predict a categorical class of an observation given other variables (features). For example:\n",
    "\n",
    "- Classifying an email as \"spam\" or \"not spam\" \n",
    "- Classifying a medical test as \"positive\" or \"negative\"\n",
    "- Classifying a bank transaction as fraudulent or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82386eb6-16f3-4ca4-8417-c697eaaeaaf8",
   "metadata": {},
   "source": [
    "Suppose we have past data of cancer tumour cell diagnosis labelled \"benign\" and \"malignant\". Do you think a new cell with Concavity = 3.3 and Perimeter = 0.2 would be malignant? How did you decide?\n",
    "\n",
    "<center><img src=\"https://datasciencebook.ca/_main_files/figure-html/05-multiknn-3-1.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f836d6c-4e75-48d5-94af-0b10cb452e8f",
   "metadata": {},
   "source": [
    "#### What kind of data analysis question is this?\n",
    "\n",
    "Descriptive, exploratory, predictive, inferential, causal, or mechanistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef0c4d-fef0-48c5-a548-9c4d9859d888",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Training and Test Sets\n",
    "\n",
    "When building a machine learning model, typically we start by dividing our data into two sets:\n",
    "1) Training set\n",
    "2) Test set\n",
    "    \n",
    "The **training set** is a subset of our data that is used is to train or teach our model to perform sort of predictive task. Then, using our **test set**, we can evaluate how well our model performs on unseen data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7830171a-fb18-425a-9b82-931772d9390c",
   "metadata": {},
   "source": [
    "There are two important things to do when splitting data.\n",
    "\n",
    "1. **Shuffling:** randomly reorder the data before splitting\n",
    "2. **Stratification:** make sure the two split subsets of data have roughly equal proportions of the different labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cccd64-b55a-462e-a0e3-22dda68cc32f",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "<img src=\"https://datasciencebook.ca/img/classification2/training_test.png\" width=\"1100\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02701a-2f92-4d4f-9a64-d6eade3dbbe0",
   "metadata": {},
   "source": [
    "#### Golden Rule of Machine Learning / Statistics:\n",
    "\n",
    "**Don't use your testing data to train your model!**\n",
    "\n",
    "Showing your classifier the labels of evaluation data is like cheating on a test; it'll look more accurate than it really is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a604659-c9c4-4b17-9f1a-8c7f5cb8d3a8",
   "metadata": {},
   "source": [
    "## 1.2 K-nearest neighbours classification\n",
    "\n",
    "*Predict the label / class for a new observation using the K closest points from our dataset.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8cdf40-48e3-4268-9f68-074c1ab7829b",
   "metadata": {},
   "source": [
    "1. Compute the distance between the new observation and each observation in our *training set*<br><br>\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-4-1.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd08d40-0d7c-4b4c-b30b-c3cb7c07ca07",
   "metadata": {},
   "source": [
    "<center>\n",
    "$\\text{Distance} = \\sqrt{(x_{\\text{new}} - x_{\\text{train}})^2 + (y_{\\text{new}} - y_{\\text{train}})^2}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad064c0-00fa-4d4e-a17b-448c0ffae9b0",
   "metadata": {},
   "source": [
    "- The new point is at perimeter $= 0.2$, concavity $= 3.3$\n",
    "- Recall that the training dataset is the sample of data used to fit the model.\n",
    "- Suppose we have a set of data and we want to predict the class of a new observation. We first want to calculate the distance between the new observation and the other points and predict the label / class for a new observation using the $K$ closest points from our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8401a-e191-4de8-b89b-07d129da9890",
   "metadata": {},
   "source": [
    "\n",
    "2. Sort the data in ascending order according to the distances\n",
    "3. Choose the top K rows as \"neighbours\"\n",
    "```\n",
    "## # A tibble: 5 x 5\n",
    "##        ID Perimeter Concavity Class dist_from_new\n",
    "##     <dbl>     <dbl>     <dbl> <fct>         <dbl>\n",
    "## 1   86409     0.241      2.65 B             0.881\n",
    "## 2  887181     0.750      2.87 M             0.980\n",
    "## 3  899667     0.623      2.54 M             1.14 \n",
    "## 4  907914     0.417      2.31 M             1.26 \n",
    "## 5 8710441    -1.16       4.04 B             1.28\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704125e7-6f7a-4f71-a312-9479d9d1a3bb",
   "metadata": {},
   "source": [
    "4. Classify the new observation based on majority vote.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-5-1.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n",
    "#### What would the predicted class be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29342540-0ea6-4f68-b12a-0267efe6dfd5",
   "metadata": {},
   "source": [
    "#### We can go beyond 2 predictors!\n",
    "\n",
    "For two observations $u, v$, each with $m$ variables (columns) labelled $1, \\dots, m$,\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "   $\\text{Distance} = \\sqrt{(u_1-v_1)^2 + (u_2-v_2)^2 + \\dots + (u_m - v_m)^2}$ \n",
    "</center>\n",
    "\n",
    "Aside from that, it's the same algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de05126-4608-4a1b-8f3b-dcedb36821d0",
   "metadata": {},
   "source": [
    "## 1.3 Standardizing Data\n",
    "<center><img src=\"img/scaling_example1.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341d8f2-f6ca-4d9d-9964-d2dc922f3568",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><img src=\"img/scaling_example2.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83665df0-27c3-475a-99cf-28ff3ab8cdde",
   "metadata": {},
   "source": [
    "- When using K-nearest neighbour classification, the scale of each variable (i.e., its size and range of values) matters. e.g. Salary (10,000+) and Age (0-100)\n",
    "- Since the classifier predicts classes by identifying observations that are nearest to it, any variables that have a large scale will have a much larger effect than variables with a small scale.\n",
    "- But just because a variable has a large scale doesn’t mean that it is more important for making accurate predictions. \n",
    "- For example, suppose you have a data set with two attributes, height (in feet) and weight (in pounds). \n",
    "\n",
    "distance1 = sqrt((202 - 200)^2 + (6 - 6)^2) = 2\n",
    "\n",
    "distance2 = sqrt((200 - 200)^2 + (8 - 6)^2) = 2\n",
    "\n",
    "Here if we calculate the distance we get 2 in both cases! A difference of 2 pounds is not that big, but a different in 2 feet is a lot. So how can we adjust for this? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a124d-2356-45b9-a72b-468a185ed6d7",
   "metadata": {},
   "source": [
    "### Nonstandardized Data vs. Standardized Data\n",
    "\n",
    "What if one variable is much larger than the other? \n",
    "\n",
    "*Standardize:* shift and scale so that the average is 0 and the standard deviation is 1.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-scaling-plt-1.png\" width=\"1200\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1563c80-1ec1-4c60-aaaa-5abf29174471",
   "metadata": {},
   "source": [
    "\n",
    "- Standardization: when all variables in a data set have a mean (center) of 0 and a standard deviation (scale) of 1, we say that the data have been standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1553cef-679d-4971-ac64-6f3de63b88f4",
   "metadata": {},
   "source": [
    "- In the plot with the original data above, its very clear that K-nearest neighbours would classify the red dot (new observation) as malignant. However, once we standardize the data, the diagnosis class labelling becomes less clear, and appears it would depend upon the choice of  \n",
    "$K$. \n",
    "- Thus, standardizing the data can change things in an important way when we are using predictive algorithms. As a rule of thumb, standardizing your data should be a part of the preprocessing you do before any predictive modelling / analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ffaac-1825-407a-8bd5-2dbc29006566",
   "metadata": {},
   "source": [
    "## 1.4 `tidymodels` package in R\n",
    "\n",
    "`tidymodels` is a collection of packages and handles computing distances, standardization, balancing, and prediction for us!\n",
    "\n",
    "<center>\n",
    "    <img src = \"https://i0.wp.com/rviews.rstudio.com/post/2019-06-14-a-gentle-intro-to-tidymodels_files/figure-html/tidymodels.png?zoom=2&w=578&ssl=1\" width=\"800\"/>\n",
    "    </center>\n",
    "Source: https://www.r-bloggers.com/2019/06/a-gentle-introduction-to-tidymodels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38908e8-29fa-46ed-a605-4424cabcb17f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m569\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m12\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (1): Class\n",
      "\u001b[32mdbl\u001b[39m (11): ID, Radius, Texture, Perimeter, Area, Smoothness, Compactness, Con...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>ID</th><th scope=col>Class</th><th scope=col>Radius</th><th scope=col>Texture</th><th scope=col>Perimeter</th><th scope=col>Area</th><th scope=col>Smoothness</th><th scope=col>Compactness</th><th scope=col>Concavity</th><th scope=col>Concave_points</th><th scope=col>Symmetry</th><th scope=col>Fractal_dimension</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>  842302</td><td>M</td><td> 1.8850310</td><td>-1.35809849</td><td> 2.3015755</td><td> 1.9994782</td><td> 1.3065367</td><td> 2.6143647</td><td> 2.1076718</td><td>2.2940576</td><td> 2.7482041</td><td> 1.9353117</td></tr>\n",
       "\t<tr><td>  842517</td><td>M</td><td> 1.8043398</td><td>-0.36887865</td><td> 1.5337764</td><td> 1.8888270</td><td>-0.3752817</td><td>-0.4300658</td><td>-0.1466200</td><td>1.0861286</td><td>-0.2436753</td><td> 0.2809428</td></tr>\n",
       "\t<tr><td>84300903</td><td>M</td><td> 1.5105411</td><td>-0.02395331</td><td> 1.3462906</td><td> 1.4550043</td><td> 0.5269438</td><td> 1.0819801</td><td> 0.8542223</td><td>1.9532817</td><td> 1.1512420</td><td> 0.2012142</td></tr>\n",
       "\t<tr><td>84348301</td><td>M</td><td>-0.2812170</td><td> 0.13386631</td><td>-0.2497196</td><td>-0.5495377</td><td> 3.3912907</td><td> 3.8899747</td><td> 1.9878392</td><td>2.1738732</td><td> 6.0407261</td><td> 4.9306719</td></tr>\n",
       "\t<tr><td>84358402</td><td>M</td><td> 1.2974336</td><td>-1.46548091</td><td> 1.3373627</td><td> 1.2196511</td><td> 0.2203623</td><td>-0.3131190</td><td> 0.6126397</td><td>0.7286181</td><td>-0.8675896</td><td>-0.3967505</td></tr>\n",
       "\t<tr><td>  843786</td><td>M</td><td>-0.1653528</td><td>-0.31356043</td><td>-0.1149083</td><td>-0.2441054</td><td> 2.0467119</td><td> 1.7201029</td><td> 1.2621327</td><td>0.9050914</td><td> 1.7525273</td><td> 2.2398308</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " ID & Class & Radius & Texture & Perimeter & Area & Smoothness & Compactness & Concavity & Concave\\_points & Symmetry & Fractal\\_dimension\\\\\n",
       " <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t   842302 & M &  1.8850310 & -1.35809849 &  2.3015755 &  1.9994782 &  1.3065367 &  2.6143647 &  2.1076718 & 2.2940576 &  2.7482041 &  1.9353117\\\\\n",
       "\t   842517 & M &  1.8043398 & -0.36887865 &  1.5337764 &  1.8888270 & -0.3752817 & -0.4300658 & -0.1466200 & 1.0861286 & -0.2436753 &  0.2809428\\\\\n",
       "\t 84300903 & M &  1.5105411 & -0.02395331 &  1.3462906 &  1.4550043 &  0.5269438 &  1.0819801 &  0.8542223 & 1.9532817 &  1.1512420 &  0.2012142\\\\\n",
       "\t 84348301 & M & -0.2812170 &  0.13386631 & -0.2497196 & -0.5495377 &  3.3912907 &  3.8899747 &  1.9878392 & 2.1738732 &  6.0407261 &  4.9306719\\\\\n",
       "\t 84358402 & M &  1.2974336 & -1.46548091 &  1.3373627 &  1.2196511 &  0.2203623 & -0.3131190 &  0.6126397 & 0.7286181 & -0.8675896 & -0.3967505\\\\\n",
       "\t   843786 & M & -0.1653528 & -0.31356043 & -0.1149083 & -0.2441054 &  2.0467119 &  1.7201029 &  1.2621327 & 0.9050914 &  1.7525273 &  2.2398308\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 12\n",
       "\n",
       "| ID &lt;dbl&gt; | Class &lt;fct&gt; | Radius &lt;dbl&gt; | Texture &lt;dbl&gt; | Perimeter &lt;dbl&gt; | Area &lt;dbl&gt; | Smoothness &lt;dbl&gt; | Compactness &lt;dbl&gt; | Concavity &lt;dbl&gt; | Concave_points &lt;dbl&gt; | Symmetry &lt;dbl&gt; | Fractal_dimension &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|   842302 | M |  1.8850310 | -1.35809849 |  2.3015755 |  1.9994782 |  1.3065367 |  2.6143647 |  2.1076718 | 2.2940576 |  2.7482041 |  1.9353117 |\n",
       "|   842517 | M |  1.8043398 | -0.36887865 |  1.5337764 |  1.8888270 | -0.3752817 | -0.4300658 | -0.1466200 | 1.0861286 | -0.2436753 |  0.2809428 |\n",
       "| 84300903 | M |  1.5105411 | -0.02395331 |  1.3462906 |  1.4550043 |  0.5269438 |  1.0819801 |  0.8542223 | 1.9532817 |  1.1512420 |  0.2012142 |\n",
       "| 84348301 | M | -0.2812170 |  0.13386631 | -0.2497196 | -0.5495377 |  3.3912907 |  3.8899747 |  1.9878392 | 2.1738732 |  6.0407261 |  4.9306719 |\n",
       "| 84358402 | M |  1.2974336 | -1.46548091 |  1.3373627 |  1.2196511 |  0.2203623 | -0.3131190 |  0.6126397 | 0.7286181 | -0.8675896 | -0.3967505 |\n",
       "|   843786 | M | -0.1653528 | -0.31356043 | -0.1149083 | -0.2441054 |  2.0467119 |  1.7201029 |  1.2621327 | 0.9050914 |  1.7525273 |  2.2398308 |\n",
       "\n"
      ],
      "text/plain": [
       "  ID       Class Radius     Texture     Perimeter  Area       Smoothness\n",
       "1   842302 M      1.8850310 -1.35809849  2.3015755  1.9994782  1.3065367\n",
       "2   842517 M      1.8043398 -0.36887865  1.5337764  1.8888270 -0.3752817\n",
       "3 84300903 M      1.5105411 -0.02395331  1.3462906  1.4550043  0.5269438\n",
       "4 84348301 M     -0.2812170  0.13386631 -0.2497196 -0.5495377  3.3912907\n",
       "5 84358402 M      1.2974336 -1.46548091  1.3373627  1.2196511  0.2203623\n",
       "6   843786 M     -0.1653528 -0.31356043 -0.1149083 -0.2441054  2.0467119\n",
       "  Compactness Concavity  Concave_points Symmetry   Fractal_dimension\n",
       "1  2.6143647   2.1076718 2.2940576       2.7482041  1.9353117       \n",
       "2 -0.4300658  -0.1466200 1.0861286      -0.2436753  0.2809428       \n",
       "3  1.0819801   0.8542223 1.9532817       1.1512420  0.2012142       \n",
       "4  3.8899747   1.9878392 2.1738732       6.0407261  4.9306719       \n",
       "5 -0.3131190   0.6126397 0.7286181      -0.8675896 -0.3967505       \n",
       "6  1.7201029   1.2621327 0.9050914       1.7525273  2.2398308       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data on cancer tumors\n",
    "tumors <- read_csv(\"data/clean-wdbc.data.csv\") |>\n",
    "    mutate(Class = as_factor(Class))\n",
    "\n",
    "head(tumors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18286c5-cd3e-417d-a9c8-3d2afa1af7cc",
   "metadata": {},
   "source": [
    "In `tidymodels`, the `recipes` package is named after cooking terms.\n",
    " \n",
    "### 1. Make a `recipe` to specify the predictors/response and preprocess the data\n",
    "1. `recipe()`:  Main argument in the formula. \n",
    "\n",
    "   Arguments: \n",
    "   - formula\n",
    "   - data\n",
    "    \n",
    "2. `prep()` & `bake()`: you can also `prep` and `bake` a recipe to see what the preprocessing does!\n",
    "\n",
    "- The `prep()` function computes everything so that the preprocessing steps can be executed\n",
    "\n",
    "- The `bake()` function takes a recipe and applies it to data and returns data\n",
    "\n",
    "- visit https://recipes.tidymodels.org/reference/index.html to see all the preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa900ebd-1e7c-4b08-83fb-f9795c2ffab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[36m──\u001b[39m \u001b[1mRecipe\u001b[22m \u001b[36m──────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\n",
      "\n",
      "\n",
      "── Inputs \n",
      "\n",
      "Number of variables by role\n",
      "\n",
      "outcome:   1\n",
      "predictor: 2\n",
      "\n",
      "\n",
      "\n",
      "── Operations \n",
      "\n",
      "\u001b[36m•\u001b[39m Centering for: \u001b[34mall_predictors()\u001b[39m\n",
      "\n",
      "\u001b[36m•\u001b[39m Scaling for: \u001b[34mall_predictors()\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data\n",
    "\n",
    "tumor_recipe <- recipe(Class ~ Perimeter + Concavity, data=tumors) |>\n",
    "                  step_center(all_predictors()) |>\n",
    "                  step_scale(all_predictors()) \n",
    "tumor_recipe           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb76c6-eddb-4b3b-b3c5-aa67f4044718",
   "metadata": {},
   "source": [
    "### 2. Build a model specification (`model_spec`) to specify the model and training algorithm\n",
    "\n",
    "1. **model type**: kind of model you want to fit\n",
    "\n",
    "2. **arguments**: model parameter values\n",
    "\n",
    "3. **engine**: underlying package the model should come from \n",
    "\n",
    "4. **mode**: type of prediction (some packages can do both classification and regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf8e1ca-068f-4422-ad9d-1d795fd29f04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K-Nearest Neighbor Model Specification (classification)\n",
       "\n",
       "Main Arguments:\n",
       "  neighbors = 3\n",
       "  weight_func = rectangular\n",
       "\n",
       "Computational engine: kknn \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a model specification using nearest_neighbor\n",
    "\n",
    "tumor_model <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) |>\n",
    "       set_engine(\"kknn\") |>\n",
    "       set_mode(\"classification\")\n",
    "\n",
    "tumor_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f92f72-807c-415e-a54f-5bb352aa2bcf",
   "metadata": {},
   "source": [
    "### 3. Put them together in a workflow and then `fit` it\n",
    "\n",
    "We may want to use our recipe across several steps as we train and test our model. To simplify this process, we can use a model workflow, which pairs a model and recipe together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23bc0e75-0227-40b2-b94a-5998063d6e92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "══ Workflow ════════════════════════════════════════════════════════════════════\n",
       "\u001b[3mPreprocessor:\u001b[23m Recipe\n",
       "\u001b[3mModel:\u001b[23m nearest_neighbor()\n",
       "\n",
       "── Preprocessor ────────────────────────────────────────────────────────────────\n",
       "2 Recipe Steps\n",
       "\n",
       "• step_center()\n",
       "• step_scale()\n",
       "\n",
       "── Model ───────────────────────────────────────────────────────────────────────\n",
       "K-Nearest Neighbor Model Specification (classification)\n",
       "\n",
       "Main Arguments:\n",
       "  neighbors = 3\n",
       "  weight_func = rectangular\n",
       "\n",
       "Computational engine: kknn \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a workflow\n",
    "\n",
    "tumor_workflow <- workflow() |>\n",
    "    add_recipe(tumor_recipe) |>\n",
    "    add_model(tumor_model)\n",
    "\n",
    "tumor_fit <- tumor_workflow |>\n",
    "    fit(data=tumors)\n",
    "\n",
    "tumor_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a2a975-fd70-4366-83bd-16153537a99e",
   "metadata": {},
   "source": [
    "### 4. Predict a new class label using `predict`\n",
    "\n",
    "`predict()` applies the recipe to the new data, then passes them to the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a8bafb-8382-44ba-b845-0f999988b3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 1 × 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.pred_class</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>M</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 1\n",
       "\\begin{tabular}{l}\n",
       " .pred\\_class\\\\\n",
       " <fct>\\\\\n",
       "\\hline\n",
       "\t M\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 1\n",
       "\n",
       "| .pred_class &lt;fct&gt; |\n",
       "|---|\n",
       "| M |\n",
       "\n"
      ],
      "text/plain": [
       "  .pred_class\n",
       "1 M          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_obs <- tibble(Perimeter = 0.2, Concavity = 3.3)\n",
    "\n",
    "predict(tumor_fit, new_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff6bbc-134d-40f2-8ab5-18b3c099659e",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-5-1.png\" width = \"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac5724-59a6-4552-adfa-b001cacad416",
   "metadata": {},
   "source": [
    "- What would happen to the prediction if we changed `Perimeter` to `-2`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c9ef2-9bb3-4f3c-a1cc-4fcd15728997",
   "metadata": {},
   "source": [
    "## 1.5 How to measure classifier performance?\n",
    "</br>\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "$$Accuracy  = \\dfrac{\\#\\; correct\\; predictions}{\\#\\; total\\; predictions}$$\n",
    "\n",
    "Downside: doesn't tell you the type of mistake being made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69ae55-d368-465b-9183-32ea7a3d2edc",
   "metadata": {},
   "source": [
    "Here is an example of confusion matrix with cancer diagnosis data we've seen before.\n",
    "\n",
    "</br>\n",
    "\n",
    "<table>\n",
    "<thead style=\"font-size: 32px\";>\n",
    "<tr class=\"header\">\n",
    "<th></th>\n",
    "<th>Truly Malignant</th>\n",
    "<th>Truly Benign</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody style=\"font-size: 32px\";>\n",
    "<tr class=\"odd\">\n",
    "<td><strong>Predicted Malignant</strong></td>\n",
    "<td>1</td>\n",
    "<td>4</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><strong>Predicted Benign</strong></td>\n",
    "<td>3</td>\n",
    "<td>57</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839337c-49e2-429e-bdf4-de893073cbd5",
   "metadata": {},
   "source": [
    "Typically we consider one of the class labels as \"positive\" - in this case the \"Malignant\" status is more interesting to researchers, hence we consider that label as \"positive\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5845a3-ffe3-44cf-ac00-ab1c9c4a73d6",
   "metadata": {},
   "source": [
    "Relabeling the above confusion matrix: \n",
    "\n",
    "</br>\n",
    "\n",
    "<table>\n",
    "<thead style=\"font-size: 32px\";>\n",
    "<tr class=\"header\">\n",
    "<th></th>\n",
    "<th>Truly Positive</th>\n",
    "<th>Truly Negative</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody style=\"font-size: 32px\";>\n",
    "<tr class=\"odd\">\n",
    "<td><strong>Predicted Positive</strong></td>\n",
    "<td>1</td>\n",
    "<td>4</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><strong>Predicted Negative</strong></td>\n",
    "<td>3</td>\n",
    "<td>57</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</br>\n",
    "\n",
    "Note that:\n",
    "* Top left cell = # correct positive predictions.\n",
    "* Top *row* = # total positive predictions.\n",
    "* Left *column* = # truly positive observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbddb77-d98a-4fca-abca-7140be5ad1e2",
   "metadata": {},
   "source": [
    "### Precision and Recall\n",
    "\n",
    "\n",
    "$$\n",
    "{Precision}  = \\dfrac{{\\#\\; correct\\; positive\\; predictions}}{{\\#\\; total\\; positive\\; predictions}} \\quad\\quad\\quad \\quad {Recall}  = \\dfrac{{\\#\\; correct\\; positive\\; predictions}}{{\\#\\; total\\; truly\\; positive\\; observations}}\n",
    "$$\n",
    "\n",
    "In the above confusion matrix, precision = 1/(1+4) and recall = 1/(1+3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdae10-9e54-4423-aab3-91c66259f9b8",
   "metadata": {},
   "source": [
    "**Precision** quantifies how many of the positive predictions the classifier made were actually positive. Intuitively, we would like a classifier to have a high precision: for a classifier with high precision, if the classifier reports that a new observation is positive, we can trust that the new observation is indeed positive. \n",
    "\n",
    "**Recall** quantifies how many of the positive observations in the test set were identified as positive. Intuitively, we would like a classifier to have a high recall: for a classifier with high recall, if there is a positive observation in the test data, we can trust that the classifier will find it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c3326-ac5e-4633-bcdb-85a6f7d455fb",
   "metadata": {},
   "source": [
    "#### In-class Question\n",
    "\n",
    "- a 99% accuracy on cancer prediction may not be very useful. Why?\n",
    "\n",
    "- If we need patients with truly malignant cancer to be diagnosed correctly, what metric should we prioritize?\n",
    "   \n",
    "- What if a classifier never guess positive except for the very few observations it is super confident in? What metric is affected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c98f2d-38a6-48fa-accb-7027030d7dfd",
   "metadata": {},
   "source": [
    "To add evaluation into our classification pipeline, we:\n",
    "\n",
    "1. Split our data into two subsets: *training data* and *testing data* (discussed above).\n",
    "2. Build the model & choose K using training data only (sometimes called tuning)\n",
    "3. Compute performance metrics (accuracy, precision, recall, etc.) by predicting labels on testing data only\n",
    "\n",
    "We'll now talk steps 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf171c32-67c8-474a-9e8d-25f42b8aee43",
   "metadata": {},
   "source": [
    "## 1.6 Choosing K (or, \"tuning'' the model)\n",
    "\n",
    "**Choosing K is part of training.** We want to choose K to maximize performance, but:\n",
    "- we can't use test data to evaluate performance (cheating!)\n",
    "- we can't use training data to evaluate performance (that's what we trained with, so poor evaluation of true performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36bbe5a-567f-4f1c-8776-70b466ef4955",
   "metadata": {},
   "source": [
    "**Solution:** Split the training data further into *training data* and *validation data sets*\n",
    "\n",
    "<br>a. Choose some candidate values of K\n",
    "<br>b. Split the **training data** into two sets - one called the **training set**, another called the **validation set**\n",
    "<br>c. For each K, train the model using **training set only**\n",
    "<br>d. Evaluate accuracy (and/or other metrics of performance) for each using **validation set only**\n",
    "<br>e. Pick the K that maximizes validation performance\n",
    "\n",
    "*But what if we get a bad training set? Just by chance?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd546c3c-ecef-4b26-8a1d-4a86672891ca",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "We can get a better estimate of performance by splitting *multiple ways* and *averaging*. Here's an example:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://datasciencebook.ca/img/classification2/cv.png\" width=\"1000\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a7648-2b9a-4d58-a64e-5b2c67d06a27",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Underfitting & Overfitting\n",
    "\n",
    "\n",
    "**Overfitting:** when your model is too sensitive to your training data; noise can influence predictions!\n",
    "\n",
    "**Underfitting:** when your model isn't sensitive enough to training data; useful information is ignored!\n",
    "\n",
    "\n",
    "<center>\n",
    "<img width=\"1000\" src=\"img/under_over_fitting.png\">\n",
    "</center>\n",
    "\n",
    "Source: http://kerckhoffs.schaathun.net/FPIA/Slides/09OF.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5cc441-8bc8-451b-bb1a-8774a2c0cdef",
   "metadata": {},
   "source": [
    "### Underfitting & Overfitting\n",
    "\n",
    "Which of these are under-, over-, and good fits? \n",
    "\n",
    "<center>\n",
    "<img width=\"1000px\" src=\"https://datasciencebook.ca/_main_files/figure-html/06-decision-grid-K-1.png\"/>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52430a9-e226-4b4c-b528-37285f911c09",
   "metadata": {},
   "source": [
    "### Underfitting & Overfitting\n",
    "For KNN: small K overfits, large K underfits, both result in lower accuracy\n",
    "\n",
    "<center>\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/06-lots-of-ks-1.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded2182-0171-4392-a77b-520cb89103bc",
   "metadata": {},
   "source": [
    "## 1.7 Compute performance metrics\n",
    "\n",
    "The role of the test data:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://datasciencebook.ca/img/classification2/ML-paradigm-test.png\" width=\"1700\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd42ee0-20c1-47e3-95dd-7db76517cfbf",
   "metadata": {},
   "source": [
    "#### The Big Picture\n",
    "\n",
    "<center>\n",
    "<img align=\"left\" src=\"https://datasciencebook.ca/img/classification2/train-test-overview.png\" width=\"1200\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f3f737-847d-4c7c-94c8-d28464e59042",
   "metadata": {},
   "source": [
    "#### Activity \n",
    "\n",
    "In a group, discuss the following prompts.\n",
    "\n",
    "- Explain what a test and training data set are in your own words\n",
    "- Explain cross-validation in your own words\n",
    "- Imagine if we train and evaluate accuracy on all the data. How can I get 100% accuracy, always?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0f4be-9da2-42b6-801d-0894286c58fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Regression \n",
    "\n",
    "What if we want to predict a quantitative value instead of a class label? \n",
    "\n",
    "<img align=\"left\" src=\"https://datasciencebook.ca/_main_files/figure-html/07-edaRegr-1.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81a543-749c-4052-a456-e247802683ec",
   "metadata": {},
   "source": [
    "E.g.: predict the price of a 2000 square foot home (from this reduced dataset)\n",
    "\n",
    "<img align=\"left\" src=\"https://datasciencebook.ca/_main_files/figure-html/07-small-eda-regr-1.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3c6ef-0092-4ffa-99fa-6f197d6874b2",
   "metadata": {},
   "source": [
    "- You can see that we have no observations of a house of size exactly 2,000 square feet\n",
    "    - What are some ways you might predict the price? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba411867-8627-49c3-82d9-0061784b3d11",
   "metadata": {},
   "source": [
    "## 2.1 K nearest neighbours regression\n",
    "\n",
    "As in k-nn classification, we find the $k$-nearest neighbours (here $k=5$) in terms of the predictors\n",
    "\n",
    "<img align=\"left\" src=\"https://datasciencebook.ca/_main_files/figure-html/07-knn3-example-1.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce010d-9e57-45cc-8655-1326b41b1c1c",
   "metadata": {},
   "source": [
    "Then we average the values for the $k$-nearest neighbours, and use that as the prediction:\n",
    "\n",
    "<img align=\"left\" src=\"https://datasciencebook.ca/_main_files/figure-html/07-predictedViz-knn-1.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f03a1-2b6c-4d9b-a5a4-a55eb5194913",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If we do that for a range of house sizes, we can draw the curve of predictions:\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/07-predict-all-1.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0dab1d-5332-4898-a951-05915848e741",
   "metadata": {},
   "source": [
    "- You can imagine doing this for all the possible input values and coming up with predictions everywhere\n",
    "- Connecting all these predictions with a line \n",
    "- one benefit is that it handles non-linearity well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbdfaa1-a955-4980-9393-48a8ff744342",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 Model Evaluation and Tuning \n",
    "\n",
    "We still have to answer these two questions:\n",
    "\n",
    "1. Is our model any good? \n",
    "\n",
    "2. How do we choose `k`? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73770050-00ed-45d0-87d0-67f619d80524",
   "metadata": {},
   "source": [
    "\n",
    "The same general strategy as in classification works here!\n",
    "\n",
    "<img align=\"left\" src=\"https://datasciencebook.ca/img/classification2/train-test-overview.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d1bd8-9395-410e-9761-f58f8017321b",
   "metadata": {},
   "source": [
    "### Is our model any good?\n",
    "\n",
    "<b><font color=\"blue\">The blue line</font></b> depicts our predictions from k-nn regression. <b><font color=\"red\">The red lines</font></b> depict the error in our predictions, i.e., the difference between the $i^\\text{th}$ test data response and our prediction $\\hat{y}_i$:\n",
    "\n",
    "<center>\n",
    "<img src=\"img/rmse.jpg\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1b982-51a9-4aab-9c15-7b42d0dffaa7",
   "metadata": {},
   "source": [
    "We now have the errors for individual points. How could you combine these errors to report a single measure of error for our model?\n",
    "\n",
    "\n",
    "We (roughly) add up these errors to evaluate our regression model\n",
    "- Not out of 1, but instead in units of the target variable (bit harder to interpret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4150e1a-16bd-4624-83a6-0b2f473f6786",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "    \n",
    "*Root Mean Squared Prediction Error* (RMSPE):\n",
    "    \n",
    "$$RMSPE = \\sqrt{\\frac{1}{n}\\sum\\limits_{i=1}^{n}(y_i - \\hat{y_i})^2}$$\n",
    "<p align=\\\"left\\\">- $n$ is the number of observations</p>\n",
    "<p align=\\\"left\\\">- $y_i$ is the observed value for the $i^\\text{th}$ test observation</p>\n",
    "<p align=\\\"left\\\">- $\\hat{y_i}$ is the predicted value for the $i^\\text{th}$ test observation</p>\n",
    "\n",
    "</td>\n",
    "<td><img src=\"img/rmse.jpg\" width=\"250\"/></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74299e82-01b9-4421-8f1c-4b6f8326f322",
   "metadata": {},
   "source": [
    "### Final model from k-nn regression\n",
    "\n",
    "For this model, RMSPE is 91,620.4. How can we interpret this?\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/07-predict-all-1.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0053002-4fd7-41cd-be84-c8d1c4aff3b4",
   "metadata": {},
   "source": [
    "Roughly, prices tend to be +/- $90,000 off that line (not that great)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d419f-f431-4019-adbb-eda2901abf5b",
   "metadata": {},
   "source": [
    "We choose $K$ roughly the same way as before:\n",
    "\n",
    "1. Cross validation:\n",
    "    - Split data into $C$ folds \n",
    "    - Train \n",
    "    - Evaluate model \n",
    "    - Pick k that gives the lowest RMSPE on validation set \n",
    "\n",
    "2. Train model on whole training dataset (not split into folds) \n",
    "\n",
    "3. Evaluate how good the predictions are using the test data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d66f8-bc5a-4895-ba35-794217d2b0dc",
   "metadata": {},
   "source": [
    "#### Discussion: Which of the following is overfitting? Underfitting? \n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/07-howK-1.png\" width=\"600\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
